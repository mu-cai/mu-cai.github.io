---
layout: post
title: Causal inference can prevent computer vision from falling into black-box deep learning
date: 2022-09-14
comments: true
tags: vision, ML, math  
description: UW-Madison 2022Fall MATH888 Project, Mu Cai
---

* TOC
{:toc}

## Homework 1

### Who am I?
My name is Mu Cai. Currently, I am a third-year Ph.D. student in the  <a href='https://cs.wisc.edu/'>Department of Computer Sciences</a>
at the <a href='https://www.wisc.edu/'>University of Wisconsin- Madison</a>, supervised by <a href='https://pages.cs.wisc.edu/~yongjaelee/'>Prof. Yong Jae Lee</a>. I got my bachelor's degree in Electrical Engineering and Automation at Xi'an Jiaotong University in 2020. My research interest lies in the intersection of deep learning and computer vision. 
I am especially interested in 3D scene understanding and self-supervised learning. You can find more information <a href='https://mu-cai.github.io/'>here</a>.


<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
  <!-- <div class="row">
    <div class="col one"> -->
        {% include figure.html path="assets/img/mucai.jpeg" class="img-fluid rounded z-depth-1" zoomable=true %}
    </div>
</div>

### What are my professional preparation/interests, background, and goals?
<!-- ### What are my professional interests or goals? -->
I am a Ph.D. student with a computer science background. I am also interested in mathematics-driven data science, 
where math (will) become my minor. Most of the time, I use deep learning, the well-known black box but powerful
tool, to empirically improve the performance of computer vision problems.
 I am passionate about solving 
**real world** problems that better serve people, such as 3D perception in autonomous driving.
However, current deep learning-based approaches may not reveal
 the underline relationship between objects and labels. For example, recent studies found that
 the irrelevant background could be an informative feature when recognizing the foreground objects,
 known as <a href="http://lgmoneda.github.io/2021/01/12/spurious-correlation-ml-and-causality.html">supurious correlation</a>.
A straightforward idea is: can we use the well-established causal inference to help improve the reliability of deep learning? 


<div class="row justify-content-sm-center">
    <div class="col-sm-8 mt-3 mt-md-0">
<!-- <div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0"> -->
  <!-- <div class="row">
    <div class="col one"> -->
        {% include figure.html path="assets/img/sup_cor.jpeg" class="img-fluid rounded z-depth-1" zoomable=true %}
    </div>
</div>


### Why am I interested in causal inference?
Therefore, the causal inference may provide us with a way to build an interpretable 
computer vision framework. Other areas, such as vision-question-answering (VQA),
can also be equipped with causal inference to improve both final performance and 
interpretation. 


## Homework 2

### What question do you want to answer? And why is it important to answer it?

<!-- In modern computer vision,  -->
Deep learning has achieved great success in a wide spread of patter recognition problems, including 
computer vision, natural language understanding, and reinforcement. However, deep neural networks have been criticised 
as a "function approximator", i.e., it doesn't learn the true "intelligence". Instead, neural networks 
could just be a mapping from the feature to the label for the majority samples. 
Therefore, the under-represented groups may be incorrrectly predicted in a biased way.
 For example, here we consider a computer vision task called scene graph generation. We are given the objects and
 their bounding boxes. 

<div class="row justify-content-sm-center">
    <div class="col-sm-8 mt-3 mt-md-0">
<!-- <div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0"> -->
  <!-- <div class="row">
    <div class="col one"> -->
        {% include figure.html path="assets/img/input.jpg" class="img-fluid rounded z-depth-1" zoomable=true %}
    </div>
</div>

We are supposed to generate a scene graph that describes the relationship between the objetcs, as the 
right figure shows in the below image. However, actually we can only get the left biased scene graph where 
the descriptions are vague, and doesn't represent the accurate action or location information. 
For example, in the biased generations, there are a lot of words like "on, has, near", instead of the 
correct desprition like "behind, parked on".


<div class="row justify-content-sm-center">
    <div class="col-sm-0 mt-0 mt-md-0">
<!-- <div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0"> -->
  <!-- <div class="row">
    <div class="col one"> -->
        {% include figure.html path="assets/img/baised_prediction.jpg" class="img-fluid rounded z-depth-1" zoomable=true %}
    </div>
</div>

Why could this happen? The major reason is that for the ease of annotation, most of the text descriptions 
in the training set is composed of the common words like "has, on, wearing". Therefore, neural networks just 
learn such common words, and may not reflect the under represented actions/relationships. Therefore, it is 
important to correctly represent the scene graph using proper inference scheme.

<div class="row justify-content-sm-center">
    <div class="col-sm-8 mt-3 mt-md-0">
<!-- <div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0"> -->
  <!-- <div class="row">
    <div class="col one"> -->
        {% include figure.html path="assets/img/class_dist.jpg" class="img-fluid rounded z-depth-1" zoomable=true %}
    </div>
</div>

Causal inference can be a great fit for this problem. Given the objects, how can we find 
proper relationship between them? We may use intervention model or the counterfactual causality 
to tackle this problem. We can also expand our anaylsis to other vision tasks like Vision-Question-Answer (VQA).

### What (observed or unobserved) random variables are needed to fully model the problem?

Here we need 4 random variables to  fully model our problem. They are all observed variables under
 the current problem setting. Here $$I$$ denotes the image, which can be represented as the high level
  semantic features from a feature extractor backbone. $$X$$ denotes the object features, which is also 
  the feature maps in the deep neural network. $$Z$$ denotes the object labels. $$Y$$ denotes the predicated logits.

<div class="row justify-content-sm-center">
    <div class="col-sm-8 mt-3 mt-md-0">
<!-- <div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0"> -->
  <!-- <div class="row">
    <div class="col one"> -->
        {% include figure.html path="assets/img/graph.png" class="img-fluid rounded z-depth-1" zoomable=true %}
    </div>
</div>



### What is the causal effect that you wish to study?
Here I want to study the Total Direct Effect [[Tang et al. 2020]](#Tang_et_al_20). 

$$
T D E=Y_x(u)-Y_{\bar{x}, z}(u),
$$

where $$ Y_x(u) $$ is the observed outcome. Here I would like to use counterfactual causility to conduct analysis, 
thus the first term is from the original graph and the second
one is from the counterfactual.

### What are your working hypotheses about the relationship between variables?

Here I am also working with DAG. From my problem setting, we know that all edges are directed, and there are no  cycles. 
Therefore, we can say that it has a topological or causal ordering.


---
# References
---
- <a name="Ren_et_al_20"></a> **\[Ren et al. 2015\]**  Ren, Shaoqing, Kaiming He, Ross Girshick, and Jian Sun "*[Faster r-cnn: Towards real-time object detection with region proposal networks](https://papers.nips.cc/paper/2015/file/14bfa6bb14875e45bba028a21ed38046-Paper.pdf)*", Advances in neural information processing systems 28 (2015)
- <a name="Wang_et_al_20"></a> **\[Wang et al. 2020\]**  Wang, Tan, Jianqiang Huang, Hanwang Zhang, and Qianru Sun "*[Visual commonsense r-cnn](https://openaccess.thecvf.com/content_CVPR_2020/papers/Wang_Visual_Commonsense_R-CNN_CVPR_2020_paper.pdf)*", In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 10760-10770. 2020
- <a name="Tang_et_al_20"></a> **\[Tang et al. 2015\]**   Tang, Kaihua, Yulei Niu, Jianqiang Huang, Jiaxin Shi, and Hanwang Zhang"*[Unbiased scene graph generation from biased training.]()*", In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pp. 3716-3725. 2020


