---
 # preview={vos.png},
---

 @article{du2022vos,
      title={VOS: Learning What You Don’t Know by Virtual Outlier Synthesis}, 
      author={Du, Xuefeng and Wang, Zhaoning and Cai, Mu and Li, Yixuan},
      journal={Proceedings of the International Conference on Learning Representations},
      year={2022},
      selected={true},
      abbr={ICLR},
       abstract      = {Out-of-distribution (OOD) detection has received much attention lately due to its importance in the safe deployment of neural networks. One of the key challenges is that models lack supervision signals from unknown data, and as a result, can produce overconfident predictions on OOD data. Previous approaches rely on real outlier datasets for model regularization, which can be costly and sometimes infeasible to obtain in practice. In this paper, we present VOS, a novel framework for OOD detection by adaptively synthesizing virtual outliers that can meaningfully regularize the model's decision boundary during training. Specifically, VOS samples virtual outliers from the low-likelihood region of the class-conditional distribution estimated in the feature space. Alongside, we introduce a novel unknown-aware training objective, which contrastively shapes the uncertainty space between the ID data and synthesized outlier data. VOS achieves competitive performance on both object detection and image classification models, reducing the FPR95 by up to 9.36% compared to the previous best method on object detectors. },
  pdf           = {https://arxiv.org/abs/2202.01197},
  code          = {https://github.com/deeplearning-wisc/vos},
}

@article{liu2022masked,
  title={Masked Discrimination for Self-Supervised Learning on Point Clouds},
  author={Liu, Haotian and Cai, Mu and Lee, Yong Jae},
  journal={Proceedings of the European Conference on Computer Vision (ECCV)},
  year={2022},
  selected={true},
  abbr={ECCV},
  abstract      = {Masked autoencoding has achieved great success for self-supervised learning in
   the image and language domains. However, mask based pretraining has yet to show benefits
    for point cloud understanding, likely due to standard backbones like PointNet
     being unable to properly handle the training versus testing distribution mismatch
      introduced by masking during training. In this paper, we bridge this gap by proposing a 
      discriminative mask pretraining Transformer framework, MaskPoint, for point clouds.
       Our key idea is to represent the point cloud as discrete occupancy values (1 if part of the point cloud; 0 if not), and perform simple binary classification between masked object points and sampled noise points as the proxy task. In this way, our approach is robust to the point sampling variance in point clouds, and facilitates learning rich representations. We evaluate our pretrained models across several downstream tasks, including 3D shape classification, segmentation, and real-word object detection, and demonstrate state-of-the-art results while achieving a significant pretraining speedup (e.g., 4.1x on ScanNet) compared to the prior state-of-the-art Transformer baseline.},
  pdf           = {https://arxiv.org/abs/2203.11183},
  code          = {https://github.com/haotian-liu/MaskPoint},
}


@article{cai-wacv2023,
  title = {Out-of-distribution Detection via Frequency-regularized Generative Models},
  author = {Cai, Mu and Li, Yixuan},
  journal = {Winter Conference on Applications of Computer Vision (WACV)},
  year = {2023},
  selected={true},
  abbr={WACV},
  abstract      = {Modern deep generative models can assign high likelihood to inputs drawn from outside the training distribution, posing threats to models in open-world deployments. While much research attention has been placed on defining new test-time measures of OOD uncertainty, these methods do not fundamentally change how deep generative models are regularized and optimized in training. In particular, generative models are shown to overly rely on the background information to estimate the likelihood. To address the issue, we propose a novel frequency-regularized learning FRL framework for OOD detection, which incorporates high-frequency information into training and guides the model to focus on semantically relevant features. FRL effectively improves performance on a wide range of generative architectures, including variational auto-encoder, GLOW, and PixelCNN++. On a new large-scale evaluation task, FRL achieves the state-of-the-art performance, outperforming a strong baseline Likelihood Regret by 10.7% (AUROC) while achieving 147× faster inference speed. Extensive ablations show that FRL improves the OOD detection performance while preserving the image generation quality.},
  pdf           = {https://arxiv.org/abs/2208.09083},
  code          = {https://github.com/mu-cai/FRL},
}

@article{cai2021frequency,
title={Frequency Domain Image Translation: More Photo-realistic, Better Identity-preserving},
author={Cai, Mu and Zhang, Hong and Huang, Huijuan and Geng, Qichuan and Li, Yixuan and Huang, Gao},
journal={In Proceedings of International Conference on Computer Vision (ICCV)},
year={2021},
selected={true},
      abbr={ICCV},
          abstract      = {Image-to-image translation has been revolutionized with GAN-based methods. However, existing methods lack the ability to preserve the identity of the source domain. As a result, synthesized images can often over-adapt to the reference domain, losing important structural characteristics and suffering from suboptimal visual quality. To solve these challenges, we propose a novel frequency domain image translation (FDIT) framework, exploiting frequency information for enhancing the image generation process. Our key idea is to decompose the image into low-frequency and high-frequency components, where the high-frequency feature captures object structure akin to the identity. Our training objective facilitates the preservation of frequency information in both pixel space and Fourier spectral space. We broadly evaluate FDIT across five large-scale datasets and multiple tasks including image translation and GAN inversion. Extensive experiments and ablations show that FDIT effectively preserves the identity of the source image, and produces photo-realistic images. FDIT establishes state-of-the-art performance, reducing the average FID score by 5.6% compared to the previous best method.},
  pdf           = {https://arxiv.org/abs/2011.13611},
  video ={https://www.youtube.com/watch?v=-J756hzIRJE},
  poster = {https://www.conferenceharvester.com/uploads/harvester/presentations/YNCRXITS/YNCRXITS-PDF-1852362-1462712-1-PDF(1).pdf},
  code          = {https://github.com/mu-cai/frequency-domain-image-translation},
}


@inproceedings{sun2020game,
  title={A game-theoretic strategy-aware interaction algorithm with validation on real traffic data},
  author={Sun*, Liting and Cai*, Mu and Zhan, Wei and Tomizuka, Masayoshi},
  booktitle={2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={11038--11044},
  year={2020},
  organization={IEEE},
  selected={true},
      abbr={IROS},
          abstract      = {Interactive decision-making and motion planning
are important to safety-critical autonomous agents, particularly
when they interact with humans. Many different interaction
strategies can be exploited by humans. For instance, they
might ignore the autonomous agents, or might behave as selfish
optimizers by treating the autonomous agents as opponents, or
might assume themselves as leaders and the autonomous agents
as followers who should take responsive actions. Different
interaction strategies can lead to quite different closed-loop
dynamics, and misalignment between the human’s policy and
the autonomous agent’s belief over the policy will severely
impact both safety and efficiency. Moreover, a human’s interaction policy can change as interaction goes on. Hence,
autonomous agents need to be aware of such uncertainties on
the human policy, and integrate such information into their
decision-making and motion planning algorithms. In this paper,
we propose a policy-aware interaction strategy based on game
theory. The goal is to allow autonomous agents to estimate
humans’ interactive policies and respond consequently. We
validate the proposed algorithm with a roundabout scenario
with real traffic data. The results show that the proposed
algorithm can yield trajectories that are more similar to the
ground truth than those with fixed policies. Also, we estimate
how humans adjust their interaction strategies statistically
based on the proposed algorithm.},
  pdf           = {http://ras.papercept.net/images/temp/IROS/files/2174.pdf},
}




