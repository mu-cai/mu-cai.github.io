<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>publications | Mu  Cai</title>
    <meta name="author" content="Mu  Cai" />
    <meta name="description" content="* indicates equal contribution." />
    <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website" />

    <!-- OpenGraph -->
    <meta property="og:site_name" content="Mu  Cai" />
    <meta property="og:type" content="website" />
    <meta property="og:title" content="Mu  Cai | publications" />
    <meta property="og:url" content="http://localhost:4000/~mucai//publications/" />
    <meta property="og:description" content="* indicates equal contribution." />
    
    <meta property="og:locale" content="en" />

    <!-- Twitter card -->
    <meta name="twitter:card" content="summary" />
    <meta name="twitter:title" content="publications" />
    <meta name="twitter:description" content="* indicates equal contribution." />
    
    


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous" />

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light" />

    <!-- Styles -->
    
    <link rel="shortcut icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>⚓</text></svg>">
    
    <link rel="stylesheet" href="/~mucai/assets/css/main.css">
    <link rel="canonical" href="http://localhost:4000/~mucai/publications/">
    
    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark" />

    <script src="/~mucai/assets/js/theme.js"></script>
    <script src="/~mucai/assets/js/dark_mode.js"></script>
    

  </head>

  <!-- Body -->
  <body class="fixed-top-nav ">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="/~mucai//"><span class="font-weight-bold">Mu </span>Cai</a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/~mucai/">about</a>
              </li>
              
              <!-- Blog -->
              <li class="nav-item ">
                <a class="nav-link" href="/~mucai/blog/">blog</a>
              </li>

              <!-- Other pages -->
              <li class="nav-item active">
                <a class="nav-link" href="/~mucai/publications/">publications<span class="sr-only">(current)</span></a>
              </li>

              <!-- Toogle theme mode -->
              <li class="toggle-container">
                <button id="light-toggle" title="Change theme">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </button>
              </li>
            </ul>
          </div>
        </div>
      </nav>
    </header>

    <!-- Content -->
    <div class="container mt-5">
      <!-- page.html -->
        <div class="post">

          <header class="post-header">
            <h1 class="post-title">publications</h1>
            <p class="post-description">* indicates equal contribution.</p>
          </header>

          <article>
            <!-- _pages/publications.md -->
<div class="publications">
  <h2 class="year">2023</h2>
  <ol class="bibliography"><li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">WACV 2023</abbr></div>

        <!-- Entry bib key -->
        <div id="cai-wacv2023" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Out-of-distribution Detection via Frequency-regularized Generative Models</div>
          <!-- Author -->
          <div class="author">
          

          <a href="https://mu-cai.github.io/" target="_blank" rel="noopener noreferrer">Mu Cai</a>, and <a href="https://pages.cs.wisc.edu/~sharonli/" target="_blank" rel="noopener noreferrer">Yixuan Li</a>
</div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>IEEE/CVF Winter Conference on Applications of Computer Vision (WACV), Spotlight</em> 2023
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://arxiv.org/abs/2208.09083" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
            <a href="https://github.com/mu-cai/FRL" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Modern deep generative models can assign high likelihood to inputs drawn from outside the training distribution, posing threats to models in open-world deployments. While much research attention has been placed on defining new test-time measures of OOD uncertainty, these methods do not fundamentally change how deep generative models are regularized and optimized in training. In particular, generative models are shown to overly rely on the background information to estimate the likelihood. To address the issue, we propose a novel frequency-regularized learning FRL framework for OOD detection, which incorporates high-frequency information into training and guides the model to focus on semantically relevant features. FRL effectively improves performance on a wide range of generative architectures, including variational auto-encoder, GLOW, and PixelCNN++. On a new large-scale evaluation task, FRL achieves the state-of-the-art performance, outperforming a strong baseline Likelihood Regret by 10.7% (AUROC) while achieving 147× faster inference speed. Extensive ablations show that FRL improves the OOD detection performance while preserving the image generation quality.</p>
          </div>
        </div>
      </div>
</li></ol>

  <h2 class="year">2022</h2>
  <ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">ECCV 2022</abbr></div>

        <!-- Entry bib key -->
        <div id="liu2022masked" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Masked Discrimination for Self-Supervised Learning on Point Clouds</div>
          <!-- Author -->
          <div class="author">
          

          <a href="https://haotian-liu.github.io/" target="_blank" rel="noopener noreferrer">Haotian Liu</a>, <a href="https://mu-cai.github.io/" target="_blank" rel="noopener noreferrer">Mu Cai</a>, and <a href="https://pages.cs.wisc.edu/~yongjaelee/" target="_blank" rel="noopener noreferrer">Yong Jae Lee</a>
</div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>Proceedings of the European Conference on Computer Vision (ECCV)</em> 2022
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://arxiv.org/abs/2203.11183" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
            <a href="https://github.com/haotian-liu/MaskPoint" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Masked autoencoding has achieved great success for self-supervised learning in
   the image and language domains. However, mask based pretraining has yet to show benefits
    for point cloud understanding, likely due to standard backbones like PointNet
     being unable to properly handle the training versus testing distribution mismatch
      introduced by masking during training. In this paper, we bridge this gap by proposing a 
      discriminative mask pretraining Transformer framework, MaskPoint, for point clouds.
       Our key idea is to represent the point cloud as discrete occupancy values (1 if part of the point cloud; 0 if not), and perform simple binary classification between masked object points and sampled noise points as the proxy task. In this way, our approach is robust to the point sampling variance in point clouds, and facilitates learning rich representations. We evaluate our pretrained models across several downstream tasks, including 3D shape classification, segmentation, and real-word object detection, and demonstrate state-of-the-art results while achieving a significant pretraining speedup (e.g., 4.1x on ScanNet) compared to the prior state-of-the-art Transformer baseline.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">ICLR 2022</abbr></div>

        <!-- Entry bib key -->
        <div id="du2022vos" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">VOS: Learning What You Don’t Know by Virtual Outlier Synthesis</div>
          <!-- Author -->
          <div class="author">
          

          Xuefeng Du, Zhaoning Wang, <a href="https://mu-cai.github.io/" target="_blank" rel="noopener noreferrer">Mu Cai</a>, and <a href="https://pages.cs.wisc.edu/~sharonli/" target="_blank" rel="noopener noreferrer">Yixuan Li</a>
</div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>Proceedings of the International Conference on Learning Representations</em> 2022
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://arxiv.org/abs/2202.01197" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
            <a href="https://github.com/deeplearning-wisc/vos" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Out-of-distribution (OOD) detection has received much attention lately due to its importance in the safe deployment of neural networks. One of the key challenges is that models lack supervision signals from unknown data, and as a result, can produce overconfident predictions on OOD data. Previous approaches rely on real outlier datasets for model regularization, which can be costly and sometimes infeasible to obtain in practice. In this paper, we present VOS, a novel framework for OOD detection by adaptively synthesizing virtual outliers that can meaningfully regularize the model’s decision boundary during training. Specifically, VOS samples virtual outliers from the low-likelihood region of the class-conditional distribution estimated in the feature space. Alongside, we introduce a novel unknown-aware training objective, which contrastively shapes the uncertainty space between the ID data and synthesized outlier data. VOS achieves competitive performance on both object detection and image classification models, reducing the FPR95 by up to 9.36% compared to the previous best method on object detectors. </p>
          </div>
        </div>
      </div>
</li>
</ol>

  <h2 class="year">2021</h2>
  <ol class="bibliography"><li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">ICCV 2021</abbr></div>

        <!-- Entry bib key -->
        <div id="cai2021frequency" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Frequency Domain Image Translation: More Photo-realistic, Better Identity-preserving</div>
          <!-- Author -->
          <div class="author">
          

          <a href="https://mu-cai.github.io/" target="_blank" rel="noopener noreferrer">Mu Cai</a>, Hong Zhang, Huijuan Huang, Qichuan Geng, <a href="https://pages.cs.wisc.edu/~sharonli/" target="_blank" rel="noopener noreferrer">Yixuan Li</a>, and <a href="http://www.gaohuang.net/" target="_blank" rel="noopener noreferrer">Gao Huang</a>
</div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In Proceedings of International Conference on Computer Vision (ICCV)</em> 2021
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://arxiv.org/abs/2011.13611" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
            <a href="https://github.com/mu-cai/frequency-domain-image-translation" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
            <a href="https://www.conferenceharvester.com/uploads/harvester/presentations/YNCRXITS/YNCRXITS-PDF-1852362-1462712-1-PDF(1).pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Poster</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Image-to-image translation has been revolutionized with GAN-based methods. However, existing methods lack the ability to preserve the identity of the source domain. As a result, synthesized images can often over-adapt to the reference domain, losing important structural characteristics and suffering from suboptimal visual quality. To solve these challenges, we propose a novel frequency domain image translation (FDIT) framework, exploiting frequency information for enhancing the image generation process. Our key idea is to decompose the image into low-frequency and high-frequency components, where the high-frequency feature captures object structure akin to the identity. Our training objective facilitates the preservation of frequency information in both pixel space and Fourier spectral space. We broadly evaluate FDIT across five large-scale datasets and multiple tasks including image translation and GAN inversion. Extensive experiments and ablations show that FDIT effectively preserves the identity of the source image, and produces photo-realistic images. FDIT establishes state-of-the-art performance, reducing the average FID score by 5.6% compared to the previous best method.</p>
          </div>
        </div>
      </div>
</li></ol>

  <h2 class="year">2020</h2>
  <ol class="bibliography"><li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">IROS 2020</abbr></div>

        <!-- Entry bib key -->
        <div id="sun2020game" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">A game-theoretic strategy-aware interaction algorithm with validation on real traffic data</div>
          <!-- Author -->
          <div class="author">
          

          Liting Sun*, <a href="https://mu-cai.github.io/" target="_blank" rel="noopener noreferrer">Mu Cai*</a>, <a href="https://zhanwei.site/" target="_blank" rel="noopener noreferrer">Wei Zhan</a>, and <a href="https://msc.berkeley.edu/people/tomizuka.html" target="_blank" rel="noopener noreferrer">Masayoshi Tomizuka</a>
</div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (* equal contribution)</em> 2020
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="http://ras.papercept.net/images/temp/IROS/files/2174.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Interactive decision-making and motion planning
are important to safety-critical autonomous agents, particularly
when they interact with humans. Many different interaction
strategies can be exploited by humans. For instance, they
might ignore the autonomous agents, or might behave as selfish
optimizers by treating the autonomous agents as opponents, or
might assume themselves as leaders and the autonomous agents
as followers who should take responsive actions. Different
interaction strategies can lead to quite different closed-loop
dynamics, and misalignment between the human’s policy and
the autonomous agent’s belief over the policy will severely
impact both safety and efficiency. Moreover, a human’s interaction policy can change as interaction goes on. Hence,
autonomous agents need to be aware of such uncertainties on
the human policy, and integrate such information into their
decision-making and motion planning algorithms. In this paper,
we propose a policy-aware interaction strategy based on game
theory. The goal is to allow autonomous agents to estimate
humans’ interactive policies and respond consequently. We
validate the proposed algorithm with a roundabout scenario
with real traffic data. The results show that the proposed
algorithm can yield trajectories that are more similar to the
ground truth than those with fixed policies. Also, we estimate
how humans adjust their interaction strategies statistically
based on the proposed algorithm.</p>
          </div>
        </div>
      </div>
</li></ol>


</div>

          </article>

        </div>

    </div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        © Copyright 2022 Mu  Cai. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="noopener noreferrer">Unsplash</a>.
Last updated: September 21, 2022.
      </div>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-SyTu6CwrfOhaznYZPoolVw2rxoY7lKYKQvqbtqN93HI=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/~mucai/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
  <script defer src="/~mucai/assets/js/zoom.js"></script><!-- Load Common JS -->
  <script defer src="/~mucai/assets/js/common.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-XXXXXXXXX"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){ window.dataLayer.push(arguments); }
    gtag('js', new Date());
    gtag('config', 'UA-XXXXXXXXX');
  </script>
  </body>
</html>
